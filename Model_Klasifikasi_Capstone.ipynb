{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpsMyKJkqrYE"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_pdkaxZqw4X",
        "outputId": "2ffaaaa3-338b-4f33-b709-20c6f0cb0617"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset extracted to /content\n"
          ]
        }
      ],
      "source": [
        "# Lokasi file ZIP\n",
        "zip_path = \"/content/drive/MyDrive/data.zip\"\n",
        "extract_to = \"/content\"\n",
        "\n",
        "# Ekstraksi file ZIP\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to)\n",
        "\n",
        "print(f\"Dataset extracted to {extract_to}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66-JnSLPRZvN"
      },
      "source": [
        "#Menyiapkan dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjKkc1Mcq4_3",
        "outputId": "4b8ac954-9e2d-4e40-a4ec-13b379430888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2882 images belonging to 36 classes.\n",
            "Found 720 images belonging to 36 classes.\n"
          ]
        }
      ],
      "source": [
        "# Path ke dataset yang sudah dikelompokkan berdasarkan folder (sesuaikan path)\n",
        "dataset_dir = \"/content/data\"\n",
        "\n",
        "# Membuat ImageDataGenerator untuk latih, validasi, dan uji\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2  # Memisahkan 20% data untuk validasi\n",
        ")\n",
        "\n",
        "# Dataset latih\n",
        "train_dataset = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(224, 224),  # Ukuran gambar untuk MobileNetV2\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',  # Kelas dalam format numerik\n",
        "    subset='training'     # Data untuk pelatihan\n",
        ")\n",
        "\n",
        "# Dataset validasi\n",
        "val_dataset = train_datagen.flow_from_directory(\n",
        "    dataset_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='sparse',  # Kelas dalam format numerik\n",
        "    subset='validation'   # Data untuk validasi\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFmzR2MzRkOP"
      },
      "source": [
        "#Membuat model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "hRb_rpxaM_ks",
        "outputId": "ca7bcc81-fde3-4c17-827c-f200c54dc1db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224 (\u001b[38;5;33mFunctional\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m2,257,984\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m1,311,744\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)                  │          \u001b[38;5;34m36,900\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ mobilenetv2_1.00_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,311,744</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,900</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,606,628\u001b[0m (13.76 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,606,628</span> (13.76 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,348,644\u001b[0m (5.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,348,644</span> (5.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load pre-trained MobileNetV2 tanpa top layer\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Menonaktifkan training pada base model agar tidak terjadi overfitting\n",
        "base_model.trainable = False\n",
        "\n",
        "# Membangun model dengan menambahkan lapisan klasifikasi\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    GlobalAveragePooling2D(),  # Mengubah output dari base model menjadi vektor\n",
        "    Dense(1024, activation='relu'),  # Lapisan dense untuk klasifikasi\n",
        "    Dense(train_dataset.num_classes, activation='softmax')  # Jumlah kelas untuk prediksi\n",
        "])\n",
        "\n",
        "# Menyusun model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dhtMHljRuur"
      },
      "source": [
        "#Melatih model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kur354yirCFE",
        "outputId": "e2e0ed54-5f18-490e-f304-a528ef139ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 2s/step - accuracy: 0.2234 - loss: 3.1295 - val_accuracy: 0.6167 - val_loss: 1.6735\n",
            "Epoch 2/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 2s/step - accuracy: 0.6816 - loss: 1.4236 - val_accuracy: 0.7847 - val_loss: 1.0252\n",
            "Epoch 3/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 2s/step - accuracy: 0.7989 - loss: 0.8763 - val_accuracy: 0.8014 - val_loss: 0.8227\n",
            "Epoch 4/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 2s/step - accuracy: 0.8252 - loss: 0.6864 - val_accuracy: 0.8319 - val_loss: 0.6728\n",
            "Epoch 5/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 2s/step - accuracy: 0.8521 - loss: 0.5729 - val_accuracy: 0.8389 - val_loss: 0.6119\n",
            "Epoch 6/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 2s/step - accuracy: 0.8810 - loss: 0.4761 - val_accuracy: 0.8514 - val_loss: 0.5464\n",
            "Epoch 7/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m267s\u001b[0m 2s/step - accuracy: 0.8824 - loss: 0.4471 - val_accuracy: 0.8583 - val_loss: 0.5212\n",
            "Epoch 8/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 2s/step - accuracy: 0.8815 - loss: 0.4284 - val_accuracy: 0.8403 - val_loss: 0.5657\n",
            "Epoch 9/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 2s/step - accuracy: 0.9001 - loss: 0.3585 - val_accuracy: 0.8806 - val_loss: 0.4501\n",
            "Epoch 10/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 2s/step - accuracy: 0.9166 - loss: 0.3193 - val_accuracy: 0.8750 - val_loss: 0.4402\n"
          ]
        }
      ],
      "source": [
        "# Melatih model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,\n",
        "    validation_data=val_dataset\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0eY96wlUTMC"
      },
      "source": [
        "#Evaluasi model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qx0Z8N9UVS5",
        "outputId": "c946a4eb-0961-4b1d-bc24-6bb2a108eff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.8744 - loss: 0.4621\n",
            "Validation Accuracy: 0.88\n"
          ]
        }
      ],
      "source": [
        "val_loss, val_acc = model.evaluate(val_dataset)\n",
        "print(f\"Validation Accuracy: {val_acc:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyKZbzsoWukj",
        "outputId": "1b91fd1a-7feb-49be-fcca-e572be915711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.9136, Training Loss: 0.3201\n",
            "Validation Accuracy: 0.8639, Validation Loss: 0.4626\n",
            "Model memiliki performa yang baik.\n"
          ]
        }
      ],
      "source": [
        "# Evaluasi pada dataset pelatihan\n",
        "train_loss, train_accuracy = model.evaluate(train_dataset, verbose=0)\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}, Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "# Evaluasi pada dataset validasi\n",
        "val_loss, val_accuracy = model.evaluate(val_dataset, verbose=0)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}, Validation Loss: {val_loss:.4f}\")\n",
        "\n",
        "# Analisis Performa\n",
        "if val_accuracy < train_accuracy - 0.1:\n",
        "    print(\"Model kemungkinan overfitting.\")\n",
        "elif train_accuracy - val_accuracy < 0.05:\n",
        "    print(\"Model memiliki performa yang baik.\")\n",
        "else:\n",
        "    print(\"Model mungkin underfitting.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#finetuning"
      ],
      "metadata": {
        "id": "oFb3W5G7PdZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan fine-tuning pada beberapa layer\n",
        "base_model.trainable = True\n",
        "fine_tune_at = 100  # Mulai fine-tuning dari layer ke-100\n",
        "\n",
        "# Freeze layer sebelum fine-tuning\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Menyusun ulang model untuk fine-tuning\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Melatih model lagi dengan fine-tuning\n",
        "history_finetune = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=10,  # Melanjutkan pelatihan\n",
        "    validation_data=val_dataset\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxqU0JxRPfuw",
        "outputId": "54b81de8-2c25-43db-9f0c-ae2e8efca241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 4s/step - accuracy: 0.7297 - loss: 0.9258 - val_accuracy: 0.6056 - val_loss: 1.4923\n",
            "Epoch 2/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 3s/step - accuracy: 0.9016 - loss: 0.2913 - val_accuracy: 0.6181 - val_loss: 1.5080\n",
            "Epoch 3/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m290s\u001b[0m 3s/step - accuracy: 0.9349 - loss: 0.1987 - val_accuracy: 0.7403 - val_loss: 1.0660\n",
            "Epoch 4/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 3s/step - accuracy: 0.9484 - loss: 0.1699 - val_accuracy: 0.7667 - val_loss: 0.9099\n",
            "Epoch 5/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 3s/step - accuracy: 0.9671 - loss: 0.1103 - val_accuracy: 0.7403 - val_loss: 1.0218\n",
            "Epoch 6/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 3s/step - accuracy: 0.9582 - loss: 0.1258 - val_accuracy: 0.8000 - val_loss: 0.9081\n",
            "Epoch 7/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 3s/step - accuracy: 0.9728 - loss: 0.0875 - val_accuracy: 0.7417 - val_loss: 1.1422\n",
            "Epoch 8/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 3s/step - accuracy: 0.9711 - loss: 0.0813 - val_accuracy: 0.7972 - val_loss: 0.8741\n",
            "Epoch 9/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 3s/step - accuracy: 0.9636 - loss: 0.1129 - val_accuracy: 0.7819 - val_loss: 0.9203\n",
            "Epoch 10/10\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 4s/step - accuracy: 0.9823 - loss: 0.0554 - val_accuracy: 0.8125 - val_loss: 0.8630\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs4rSgCpUl7R"
      },
      "source": [
        "#Menyimpan model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-0xG7yOaHRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e64c0b-4685-48ab-d18f-ae650756128b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save(\"plant_disease_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pneyQPc7U3sV"
      },
      "outputs": [],
      "source": [
        "#loaded_model = tf.keras.models.load_model(\"best_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9jJbt4uaU6H"
      },
      "source": [
        "#prediksi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iq7CvfCbPe0",
        "outputId": "3a255e50-b871-4b5b-d86d-fc806eb1c17a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'Apple___Apple_scab', 1: 'Apple___Black_rot', 2: 'Apple___Cedar_apple_rust', 3: 'Apple___healthy', 4: 'Blueberry___healthy', 5: 'Cherry___Powdery_mildew', 6: 'Cherry___healthy', 7: 'Corn___Cercospora_leaf_spot Gray_leaf_spot', 8: 'Corn___Common_rust', 9: 'Corn___Northern_Leaf_Blight', 10: 'Corn___healthy', 11: 'Grape___Black_rot', 12: 'Grape___Esca_(Black_Measles)', 13: 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)', 14: 'Grape___healthy', 15: 'Orange___Haunglongbing_(Citrus_greening)', 16: 'Pepper,_bell___Bacterial_spot', 17: 'Pepper,_bell___healthy', 18: 'Potato___Early_blight', 19: 'Potato___Late_blight', 20: 'Potato___healthy', 21: 'Raspberry___healthy', 22: 'Soybean___healthy', 23: 'Squash___Powdery_mildew', 24: 'Strawberry___Leaf_scorch', 25: 'Strawberry___healthy', 26: 'Tomato___Bacterial_spot', 27: 'Tomato___Early_blight', 28: 'Tomato___Late_blight', 29: 'Tomato___Leaf_Mold', 30: 'Tomato___Septoria_leaf_spot', 31: 'Tomato___Spider_mites Two-spotted_spider_mite', 32: 'Tomato___Target_Spot', 33: 'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 34: 'Tomato___Tomato_mosaic_virus', 35: 'Tomato___healthy'}\n"
          ]
        }
      ],
      "source": [
        "# Ambil mapping kelas dari generator data latih\n",
        "class_labels = train_dataset.class_indices  # train_dataset dari ImageDataGenerator\n",
        "# Balikkan dictionary untuk memetakan indeks ke nama kelas\n",
        "class_labels = {v: k for k, v in class_labels.items()}\n",
        "print(class_labels)  # Output: {0: 'class_name1', 1: 'class_name2', ...}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vHUYjeDaRvE",
        "outputId": "25b29ac5-75cf-4671-eaab-a2be8f084b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Predicted Class: Apple___Black_rot\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Fungsi untuk memprediksi gambar\n",
        "def predict_image(img_path):\n",
        "    # Memuat dan memproses gambar\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Menambahkan batch dimension\n",
        "    img_array = img_array / 255.0  # Normalisasi gambar\n",
        "\n",
        "    # Prediksi dengan model\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = np.argmax(predictions, axis=-1)\n",
        "\n",
        "    # Ambil nama kelas berdasarkan prediksi\n",
        "    class_names = list(train_dataset.class_indices.keys())\n",
        "    predicted_class_name = class_names[predicted_class[0]]\n",
        "\n",
        "    return predicted_class_name\n",
        "\n",
        "# Contoh pemakaian\n",
        "image_path = '/content/data/Apple___Black_rot/image (10).JPG'\n",
        "predicted_class = predict_image(image_path)\n",
        "print(f\"Predicted Class: {predicted_class}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}